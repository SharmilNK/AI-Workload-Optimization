# PRD — AI Workload Optimization Pilot (one-pager)

## Problem
LLM cost and performance are unpredictable: teams default to large models for everything, causing wasted spend and latency.

## Objective
Demonstrate an AI Decision Layer that routes tasks to the cheapest sufficient model and provides observability via MuleRun → SmartQ.

## Scope (Pilot)
- Task types: classification, summarization, reasoning
- Data: public scraped docs (Wikipedia, arXiv, Gutenberg)
- Deliverables: routing_policy.md, scraper, backend stub, MuleRun event examples, SmartQ dashboard screenshots.

## Success metrics (placeholders to fill)
- % reduction in large-model calls
- Cost saved vs baseline
- Avg quality score delta vs baseline

## Stakeholders
- PM / Implementer

